{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeisyData/BIT_IA_Bootcamp/blob/main/S11_C1_Emojis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1NrJBOh4DFg"
      },
      "outputs": [],
      "source": [
        "# Notebook to release Sentiment Analysis - prediction\n",
        "# Iván Andrés Trujillo abella\n",
        "# ivantrujillo1229@gmail.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9B2pwQu4DFh"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/it-ces/Datasets/refs/heads/main/tweets(ai-page).csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install emoji --upgrade"
      ],
      "metadata": {
        "id": "S82TpmmK46RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYY9wkJi4DFi"
      },
      "outputs": [],
      "source": [
        "import emoji\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4UXFn8H4DFi"
      },
      "outputs": [],
      "source": [
        "s = '😡'\n",
        "code = 'U000{:X}'.format(ord(s))\n",
        "print(code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOHUyiVl4DFj"
      },
      "outputs": [],
      "source": [
        "matches = [\"U0001F621\", \"U0001F607\"]\n",
        "emojis = [emoji.replace('U', r\"\\U\").encode().decode('unicode-escape') for emoji in matches]\n",
        "print(emojis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjP3jRBU4DFj"
      },
      "outputs": [],
      "source": [
        "print(emoji.is_emoji(\"\\U0001F607\"))\n",
        "emoji.is_emoji(\"😡\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyvHlRwg4DFj"
      },
      "outputs": [],
      "source": [
        "emoji.distinct_emoji_list(\"\\U0001F607 hello world\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISbYWDDJ4DFj"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtNLZtmR4DFj"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzygZKVN4DFk"
      },
      "outputs": [],
      "source": [
        "df['emoticons']='None'\n",
        "for index in df.index:\n",
        "    if len(emoji.distinct_emoji_list(df.loc[index,'tweet']))>0:\n",
        "        im = emoji.distinct_emoji_list(df.loc[index,'tweet'])\n",
        "        df.loc[index, 'emoticons'] = im[0] # take the first emoticon\n",
        "\n",
        "df  = df[df['emoticons']!='None'].reset_index(drop=True)\n",
        "\n",
        "def label_emoji(emojis):\n",
        "    labels={'Angry':['🤬','😡', '😤','🤭'],\n",
        "            'Smile':['😁','🤗', '😀'],\n",
        "            'Nice':['😎','♥️','👍', '😍','👍🏾','😻','🙏🏽','🙌🏼',\n",
        "                     '👏🏻','🦾', '🤘', '💪'],\n",
        "            'No nice': ['🖕🏼','🤡','🤦','👎🏾','🥲' ,'😰'],\n",
        "            'Sad':['😔', '😩','😢','😫', '😭' ]}\n",
        "    class_name = 'Another'\n",
        "    for emoticon in emojis:\n",
        "        if emojis =='None':\n",
        "            return 'None'\n",
        "        for label in labels:\n",
        "            if emoticon in labels[label]:\n",
        "                class_name = label\n",
        "    return class_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RS9lJXP4DFk"
      },
      "outputs": [],
      "source": [
        "df['y'] = df['emoticons'].apply(lambda x: label_emoji(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPlXNtcX4DFk"
      },
      "outputs": [],
      "source": [
        "## Using regular expressions to tackle\n",
        "df['tweet'] = df['tweet'].apply(lambda x : emoji.replace_emoji(x, replace=''))\n",
        "df['tweet'] = df['tweet'].apply(lambda x : x.lower())\n",
        "df['tweet'] =df['tweet'].replace('mi[Bb]anco', \"\", regex=True)\n",
        "regex_url = \"https?:\\\\/\\\\/(?:www\\\\.)?[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}\\\\.[a-zA-Z0-9()]{1,6}\\\\b(?:[-a-zA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)$\"\n",
        "df['tweet'] = df['tweet'].replace(regex_url, \"\", regex=True)\n",
        "df['tweet'] = df['tweet'].replace(r'\\bhttps://t.co/[a-z0-9]*\\b', \"\", regex=True)\n",
        "df['tweet'] = df['tweet'].replace(r'[\\d@#]', \"\", regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vw1Hsw6P4DFk"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrEx53Dy4DFl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "## To modeling\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "\n",
        "# Logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "import re\n",
        "\n",
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHLdr8YT4DFl"
      },
      "outputs": [],
      "source": [
        "df = df[df['y']!='Another']\n",
        "df.reset_index(inplace=True, drop=True )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeU9rS434DFl"
      },
      "outputs": [],
      "source": [
        "df['y'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArtY65Yt4DFl"
      },
      "outputs": [],
      "source": [
        "df['feeling'] = np.where((df['y']=='Smile') | (df['y']=='Nice'), 'Positive', 'Negative')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuJM2fTF4DFl"
      },
      "outputs": [],
      "source": [
        "df['feeling'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itkqL7mx4DFm"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2SyPeMv4DFm"
      },
      "outputs": [],
      "source": [
        "emojis = df['emoticons'].unique()\n",
        "base_of_text={}\n",
        "for emo in emojis:\n",
        "    base_of_text[emo] = \"\".join(df[df['emoticons']==emo]['tweet'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvOPGMBb4DFm"
      },
      "outputs": [],
      "source": [
        "df['emoticons'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Btmn-L4A4DFm"
      },
      "outputs": [],
      "source": [
        "wc = WordCloud(background_color=\"white\", repeat=True)\n",
        "wc.generate(base_of_text['😡'])\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(wc, interpolation=\"bilinear\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "a_6gA5M44DFm"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stopwords.words('spanish')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_stops = set(stopwords.words('spanish'))\n",
        "en_stops"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nygq2TCb8s8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cesmY-5p4DFm"
      },
      "outputs": [],
      "source": [
        "all_words = ['There', 'is', 'a', 'tree','near','the','river', 'cómo','tan', 'alguna', 'casi', 'vaya']\n",
        "for word in all_words:\n",
        "    if word not in en_stops:\n",
        "        print(word)\n",
        "custom_stop_words = ['alguna', 'near', 'cómo',  'casi', 'vaya', ',']  # Replace with your custom stop words\n",
        "en_stops.update(custom_stop_words)\n",
        "for word in all_words:\n",
        "    if word not in en_stops:\n",
        "        print(word, 'added')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vFZnN8X4DFn"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qITzq1uC4DFn"
      },
      "outputs": [],
      "source": [
        "tweet  =  df.loc[0,'tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fs3igwSF4DFn"
      },
      "outputs": [],
      "source": [
        "custom_stop_words = ['casi', 'pronto', 'tan',  'seguro', 'cúando']  # add to improve!\n",
        "en_stops.update(custom_stop_words)\n",
        "\n",
        "def remove_stopwords(tweet):\n",
        "    new = []\n",
        "    for word in tweet.split():\n",
        "        if word not in en_stops:\n",
        "            new.append(word)\n",
        "    return \" \".join(new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyk0RABc4DFn"
      },
      "outputs": [],
      "source": [
        "remove_stopwords('cada día expreso mi inconformidad con la entidad')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rvx3xBu74DFn"
      },
      "outputs": [],
      "source": [
        "df['tweet'] =  df['tweet'].apply(lambda x : remove_stopwords(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j85mklpU4DFn"
      },
      "outputs": [],
      "source": [
        "emojis = df['emoticons'].unique()\n",
        "base_of_text={}\n",
        "for emo in emojis:\n",
        "    base_of_text[emo] = \"\".join(df[df['emoticons']==emo]['tweet'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxuU7Nin4DFn"
      },
      "outputs": [],
      "source": [
        "wc = WordCloud(background_color=\"white\", repeat=True)\n",
        "wc.generate(base_of_text['😡'])\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(wc, interpolation=\"bilinear\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d54ylMyg4DFo"
      },
      "outputs": [],
      "source": [
        "def remove_laughs(tweet):\n",
        "    new = []\n",
        "    for word in tweet.split():\n",
        "        if bool(re.fullmatch('a*ja+j[ja]*', word))==False:\n",
        "            new.append(word)\n",
        "    return ' '.join(new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRHSYNpJ4DFo"
      },
      "outputs": [],
      "source": [
        "df['tweet'] = df['tweet'].apply(lambda x : remove_laughs(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmnRDep54DFo"
      },
      "outputs": [],
      "source": [
        "def remove_term(regex, tweet):\n",
        "    new = []\n",
        "    for word in tweet.split():\n",
        "        if bool(re.fullmatch(regex, word))==False:\n",
        "            new.append(word)\n",
        "    return ' '.join(new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEoVjNSZ4DFo"
      },
      "outputs": [],
      "source": [
        "remove_term('app', 'app no funciona')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8rG2TEh4DFp"
      },
      "outputs": [],
      "source": [
        "df['tweet'] =  df['tweet'].apply(lambda x: remove_term('miB[b]anco',x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnAxfhVD4DFp"
      },
      "outputs": [],
      "source": [
        "emojis = df['emoticons'].unique()\n",
        "base_of_text={}\n",
        "for emo in emojis:\n",
        "    base_of_text[emo] = \"\".join(df[df['emoticons']==emo]['tweet'].values)\n",
        "wc = WordCloud(background_color=\"white\", repeat=True)\n",
        "wc.generate(base_of_text['😡'])\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(wc, interpolation=\"bilinear\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8Xd6Prf4DFp"
      },
      "outputs": [],
      "source": [
        "df['feeling'] = np.where(df['feeling']=='Positive',1 ,0)\n",
        "X  = df['tweet']\n",
        "y = df['feeling']\n",
        "X_train, X_test, y_train, y_test  = model_selection.train_test_split(X,y, test_size = 0.25,  random_state=666)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXqE-44W4DFp"
      },
      "outputs": [],
      "source": [
        "df= df[df['tweet'].apply(lambda tweet: len(str(tweet))!=0)]\n",
        "df.reset_index(inplace=True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u53fUJug4DFq"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwx8cFGK4DFq"
      },
      "outputs": [],
      "source": [
        "### Logistic Regression\n",
        "def grid_search_lr(X_train, y_train):\n",
        "    model = LogisticRegression(random_state=666, max_iter=1000)\n",
        "    class_weight =  [{1:0.5, 0:0.5}]\n",
        "    solvers = ['liblinear']\n",
        "    penalty = ['l2','l1', ]\n",
        "    c_values = [1000, 100,50, 10,1,0.1 ]\n",
        "    grid = dict(solver=solvers,penalty=penalty,C=c_values, class_weight= class_weight)\n",
        "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
        "    scorer = make_scorer(f1_score, average = 'weighted')\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv,\n",
        "                           scoring=scorer,error_score=0)\n",
        "    grid_result = grid_search.fit(X_train, y_train)\n",
        "    best_params = grid_result.best_params_\n",
        "    return best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27VPfBwt4DFq"
      },
      "outputs": [],
      "source": [
        "# vectorization\n",
        "vect = CountVectorizer().fit(X_train)\n",
        "vect.get_feature_names_out()\n",
        "X_train_vectorized = vect.transform(X_train)\n",
        "params = grid_search_lr(X_train_vectorized, y_train)\n",
        "\n",
        "# We are going to predict\n",
        "model = LogisticRegression(penalty = params['penalty'],\n",
        "                           class_weight=params['class_weight'],\n",
        "                           solver = params['solver'],\n",
        "                           C = params['C'],\n",
        "                           random_state =123)\n",
        "print(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9gevxjn4DFq"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train_vectorized, y_train)\n",
        "preds = model.predict(vect.transform(X_test))\n",
        "print(classification_report(y_test, preds))\n",
        "import numpy as np\n",
        "f_names = np.array(vect.get_feature_names_out())\n",
        "sorted_coef  = model.coef_[0].argsort()\n",
        "print(f_names[sorted_coef][0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxZd-TO74DFq"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_teCpZi4DFq"
      },
      "outputs": [],
      "source": [
        "X_train = pd.DataFrame(X_train)\n",
        "rus = RandomUnderSampler(random_state=1234)\n",
        "X_train, y_train = rus.fit_resample(X_train, y_train)\n",
        "X_train = X_train['tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jqR73wz4DFq"
      },
      "outputs": [],
      "source": [
        "vect = CountVectorizer().fit(X_train)\n",
        "#vect.get_feature_names_out()\n",
        "X_train_vectorized = vect.transform(X_train)\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "preds = model.predict(vect.transform(X_test))\n",
        "print(classification_report(y_test, preds))\n",
        "import numpy as np\n",
        "f_names = np.array(vect.get_feature_names_out())\n",
        "sorted_coef  = model.coef_[0].argsort()\n",
        "print(f_names[sorted_coef][0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GGgrEOS4DFr"
      },
      "outputs": [],
      "source": [
        "def grid_RandomForest(X_train, y_train):\n",
        "  model = RandomForestClassifier(random_state=0)\n",
        "  n_estimators = np.arange(10,100,1)\n",
        "  criterion = ['gini', 'entropy', 'log_loss']\n",
        "  min_samples_split = [0.05, 0.1,]\n",
        "  max_depth = [2,3,4,10]\n",
        "  grid = dict(n_estimators = n_estimators, criterion = criterion,\n",
        "              min_samples_split = min_samples_split, max_depth = max_depth)\n",
        "  cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
        "  grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv,\n",
        "                            scoring='f1',error_score='raise')\n",
        "  grid_result = grid_search.fit(X_train, y_train)\n",
        "  return  grid_result.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-fx_BGr4DFr"
      },
      "outputs": [],
      "source": [
        "best_model = grid_RandomForest(X_train_vectorized, y_train)\n",
        "preds = best_model.predict(vect.transform(X_test))\n",
        "print(classification_report(y_test, preds))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}